# -*- coding: utf-8 -*-
"""distance and center.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gSP8vsESHXQohsciCoSlWTg7tMHzTPQc
"""

from PIL import Image, ImageStat
from google.colab.patches import cv2_imshow as cvs
import math
import numpy as np
import cv2 as cv
import numpy as np
from matplotlib import pyplot as plt
import os
!pip install mediapipe

import mediapipe as mp
import cv2

def euclideanDistance(coordinate1, coordinate2):
    return pow(pow(coordinate1[0] - coordinate2[0], 2) + pow(coordinate1[1] - coordinate2[1], 2), .5)

for p in os.listdir("/content/drive/MyDrive/intershipdeepv/dataset/Untitledfolder/Sign_hand_object_dataset_sangeeth"):
  t=[]
  for l in os.listdir("/content/drive/MyDrive/intershipdeepv/dataset/Untitledfolder/Sign_hand_object_dataset_sangeeth/{}".format(p)):
    iii=[ ]
    for q in os.listdir("/content/drive/MyDrive/intershipdeepv/dataset/Untitledfolder/Sign_hand_object_dataset_sangeeth/{}/{}".format(p,l)):
        iii=[ ]
        frmd=("/content/drive/MyDrive/intershipdeepv/dataset/Untitledfolder/Sign_hand_object_dataset_sangeeth/{}/{}/{}".format(p,l,q))
        mp_drawing = mp.solutions.drawing_utils
        mp_drawing_styles = mp.solutions.drawing_styles
        mp_pose = mp.solutions.pose
        IMAGE_FILES = []
        BG_COLOR = (192, 192, 192) # gray
        with mp_pose.Pose(
              static_image_mode=True,
              model_complexity=2,
              enable_segmentation=True,
              min_detection_confidence=0.5) as pose:
         image = cv2.imread(frmd)
         image_height, image_width, _ = image.shape
         # Convert the BGR image to RGB before processing.
         results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
         if not results.pose_landmarks:
            print("no one")
         leftshouder=(  
         results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].x * image_width,
         results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].y * image_height );
         la1=results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].x * image_width
         la2=results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].y * image_height
         print(la1)
         print(la2)
         print(leftshouder)
         rightshouder=(
         results.pose_landmarks.landmark[mp_pose.PoseLandmark(12).value].x * image_width ,
         results.pose_landmarks.landmark[mp_pose.PoseLandmark(12).value].y * image_height
         );
         ra1=results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].x * image_width
         ra2=results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].y * image_height
        print(rightshouder)
        annotated_image = image.copy()
        mp_drawing.draw_landmarks(
               annotated_image,
               results.pose_landmarks,
               mp_pose.POSE_CONNECTIONS,
               landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())
        cvs(annotated_image)
        import math
        a=euclideanDistance(leftshouder, rightshouder)
        print(a)
        per=50*(int(a)/100)
        per
        imagefar=(int(a)/int(image_width))*100
        imagefar
        print(imagefar)
        if imagefar>65:
         print("stay bit far from camra")
        if imagefar<10:
         print("ur to far")
        la=euclideanDistance((0,leftshouder[1]),leftshouder) 
        print(la) 
#dist btw rightshoulder
        ra=euclideanDistance(rightshouder,(image_width,rightshouder[1])) 
        print(ra) 
    #convert both dist to round 
        fra=(round(int(ra)/int(image_width)))*10
        print(fra)
        lra=(round(int(la)/int(image_width)))*10
        print(fra)
        if lra>fra:
          print("move left")
        elif fra>lra:
          print("move right")
        else:
         print("ur at the center") 
        #cpic=(len(os.listdir(frmd)))
        lw=(
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(15).value].x * image_width ,
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(15).value].y * image_height
        ); 
        rw=(
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(16).value].x * image_width ,
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(16).value].y * image_height
        );
        lp=(
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(17).value].x * image_width ,
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(17).value].y * image_height
        );
        rp=(
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(18).value].x * image_width ,
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(18).value].y * image_height
        );
        li=(
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(19).value].x * image_width ,
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(19).value].y * image_height
        );
        ri=(
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(20).value].x * image_width ,
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(20).value].y * image_height
        );
        lt=(
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(21).value].x * image_width ,
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(21).value].y * image_height
        );
        rt=(
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(22).value].x * image_width ,
        results.pose_landmarks.landmark[mp_pose.PoseLandmark(22).value].y * image_height
        );
        lhandp=[]
        rhandp=[]
        lhandp.append(lw)
        lhandp.append(lp)
        lhandp.append(li)
        lhandp.append(lt)
        lhpa = np.average(lhandp,axis=0)
        rhandp.append(rw)
        rhandp.append(rp)
        rhandp.append(ri)
        rhandp.append(rt)
        rhpa = np.average(rhandp,axis=0)
        print("left")
        print(lhandp)
        print(lhpa)
        print("right")
        print(rhandp)
        print(rhpa)
        print("kkkkkkkkkkkkkkkkkkkkk")
        lmg=euclideanDistance((0,lhpa[1]),lhpa) 
        rmg=euclideanDistance((0,rhpa[1]),rhpa) 
        print(lmg)
        print(rmg)

def euclideanDistance(coordinate1, coordinate2):
    return pow(pow(coordinate1[0] - coordinate2[0], 2) + pow(coordinate1[1] - coordinate2[1], 2), .5)

for p in os.listdir("/content/drive/MyDrive/intershipdeepv/dataset/Untitledfolder/Sign_hand_object_dataset_sangeeth"):
  t=[]
  for l in os.listdir("/content/drive/MyDrive/intershipdeepv/dataset/Untitledfolder/Sign_hand_object_dataset_sangeeth/{}".format(p)):
      for q in os.listdir("/content/drive/MyDrive/intershipdeepv/dataset/Untitledfolder/Sign_hand_object_dataset_sangeeth/{}/{}".format(p,l)):

        frmd=("/content/drive/MyDrive/intershipdeepv/dataset/Untitledfolder/Sign_hand_object_dataset_sangeeth/{}/{}/{}".format(p,l,q))
        mp_drawing = mp.solutions.drawing_utils
        mp_drawing_styles = mp.solutions.drawing_styles
        mp_pose = mp.solutions.pose
        IMAGE_FILES = []
        BG_COLOR = (192, 192, 192) # gray
        with mp_pose.Pose(
              static_image_mode=True,
              model_complexity=2,
              enable_segmentation=True,
              min_detection_confidence=0.5) as pose:
         image = cv2.imread(frmd)
         image_height, image_width, _ = image.shape
         # Convert the BGR image to RGB before processing.
         results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
         if not results.pose_landmarks:
            print("no one")
         leftshouder=(  
         results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].x * image_width,
         results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].y * image_height );
         la1=results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].x * image_width
         la2=results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].y * image_height
         print(la1)
         print(la2)
         print(leftshouder)
         rightshouder=(
         results.pose_landmarks.landmark[mp_pose.PoseLandmark(12).value].x * image_width ,
         results.pose_landmarks.landmark[mp_pose.PoseLandmark(12).value].y * image_height
         );
         ra1=results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].x * image_width
         ra2=results.pose_landmarks.landmark[mp_pose.PoseLandmark(11).value].y * image_height
        print(rightshouder)
        annotated_image = image.copy()
        mp_drawing.draw_landmarks(
               annotated_image,
               results.pose_landmarks,
               mp_pose.POSE_CONNECTIONS,
               landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())
        cvs(annotated_image)
        import math
        a=euclideanDistance(leftshouder, rightshouder)
        print(a)
        per=50*(int(a)/100)
        per
        imagefar=(int(a)/int(image_width))*100
        imagefar
        print(imagefar)
        if imagefar>90:
         print("stay bit far from camra")
        if imagefar<10:
         print("ur to far")
  ##dist btw x=o to leftshoulder
        la=euclideanDistance((0,leftshouder[1]),leftshouder) 
        print(la) 
#dist btw rightshoulder
        ra=euclideanDistance(rightshouder,(image_width,rightshouder[1])) 
        print(ra) 
    #convert both dist to round 
        fra=(round(int(ra)/int(image_width)))*10
        print(fra)
        lra=(round(int(la)/int(image_width)))*10
        print(fra)
        if lra>fra:
          print("move left")
        elif fra>lra:
          print("move right")
        else:
         print("ur at the center")

